{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParnianH98/CNN-Convolutional-Neural-Network-/blob/main/Neural_Network_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz4sXbxbYYQu",
        "outputId": "e8bc4a36-4964-4035-cde4-f898f405a938"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJTKnaa05RkE"
      },
      "source": [
        "load data: train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgf1qlf84huF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4b7ec568-b2b9-4ca9-ba41-754dbaf8c7b7"
      },
      "source": [
        "data = pd.read_csv(r'/gdrive/My Drive/AI HW/Neural Network optimization/train.csv')\n",
        "data.head(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmYw3SV_8ICL"
      },
      "source": [
        "##preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joiAeQvc9FrH"
      },
      "source": [
        "check for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQT_9_FwRbxU"
      },
      "source": [
        "no not available data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkOFlv0N8D_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2922ced3-7129-49b6-a43b-1d3b688c3425"
      },
      "source": [
        "data.isnull().any().describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       785\n",
              "unique        1\n",
              "top       False\n",
              "freq        785\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir_NjoawRpAq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "bea355a0-70ca-4ee4-a688-c6526e7f736d"
      },
      "source": [
        "random_seed = 2\n",
        "\n",
        "\n",
        "Y_train = data[\"label\"]\n",
        "\n",
        "# Drop 'label' column\n",
        "X_train = data.drop(labels = [\"label\"],axis = 1) \n",
        "\n",
        "# free some space\n",
        "del data \n",
        "\n",
        "g = sns.countplot(y=Y_train)\n",
        "\n",
        "Y_train.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd-d0yLRRuhA"
      },
      "source": [
        "almost balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTOLH7fBKeOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa18ca1-3db4-4191-e1f3-fbea2ea09801"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM3s1fIHKkdO"
      },
      "source": [
        "# X_test.shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8t5-kJN86q7"
      },
      "source": [
        "normalaize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WZXUlGbRsH9"
      },
      "source": [
        "X_train = X_train / 255.0\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWZWAphN9igV"
      },
      "source": [
        "# # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1) ---> not RGB\n",
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "# X_test = X_test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK9Sj0m2935m"
      },
      "source": [
        "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqfQ7Vsv-VuN"
      },
      "source": [
        "split training and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bogzR9cNR_dr"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BtUmV1-lHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4b5d66b7-590c-4108-9f30-4b50bf912f30"
      },
      "source": [
        "# Some examples\n",
        "g = plt.imshow(X_train[0][:,:,0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN5ElEQVR4nO3df+xV9X3H8ddrDCFSdTAcoZTRHyqNWTa6fos2NQuNWRVsgl0aU7IYtlC+ppH0R5pmxqVq3T9mW2uqMaagtNRQm6bVyApdywiNaWKZXx1D/EF1FlYQ+dqwFbqmCPS9P76H5lv9nnO+3HPuD77v5yP55t57Pvfc8+bUV8+9933P+TgiBGDq+71+FwCgNwg7kARhB5Ig7EAShB1I4vd7ubHzPCNmalYvNwmk8mv9n16PE55orFHYbV8r6cuSpkl6ICLuqnr+TM3SFb66ySYBVNgVO0rHOn4bb3uapPskLZd0uaRVti/v9PUAdFeTz+xLJb0UES9HxOuSvilpZTtlAWhbk7AvkPSzcY8PFst+h+1h2yO2R07qRIPNAWii69/GR8T6iBiKiKHpmtHtzQEo0STshyQtHPf4bcUyAAOoSdiflHSp7XfYPk/SxyRtaacsAG3ruPUWEadsr5P0fY213jZGxLOtVQagVY367BGxTdK2lmoB0EX8XBZIgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGs3iiqnvxPL3VY4f+Kvq9X963YbSsU++Uv3a/z66qHJ85r2zK8dnfO/JyvFsGoXd9n5JxyWdlnQqIobaKApA+9o4sn8wIn7ewusA6CI+swNJNA17SPqB7adsD0/0BNvDtkdsj5zUiYabA9Cppm/jr4qIQ7b/SNJ22y9ExOPjnxAR6yWtl6QLPScabg9Ahxod2SPiUHE7KulRSUvbKApA+zoOu+1Zti84c1/ShyTtbaswAO1q8jZ+nqRHbZ95nW9ExL+2UhV65sCd768cPzH/VOX4okeqX/+atUsqRk9Wrnvyposrxz9/71crx9ftvLF07LK1+XrwHYc9Il6W9Gct1gKgi2i9AUkQdiAJwg4kQdiBJAg7kIQjevejtgs9J67w1T3bXhbTFl9SOnb07up1/3ekur216LYnOimpJ6r+3VL9v73KRSte6nzlPtoVO3QsjnqiMY7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEl5KeAi7ZfKB07F/+o+oUU+myAe6j1zm9r7oXPucz5X34m7d+t3Ld+xZ/uNG2BxFHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Igj77OaBu2uRr/uCh0rF9a6sv1zyVHVlWfq7+def/unLde87BPnodjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAR99nPADx/cUDm+bM3a0rEZmrpTE9f9/uCp2+/v+LW//8ruyvErd3+0cnwQrztfe2S3vdH2qO2945bNsb3d9ovF7ezulgmgqcm8jf+apGvfsOwWSTsi4lJJO4rHAAZYbdgj4nFJR9+weKWkTcX9TZKub7kuAC3r9DP7vIg4XNx/VdK8sifaHpY0LEkzdX6HmwPQVONv42NsZsjS2SEjYn1EDEXE0HTNaLo5AB3qNOxHbM+XpOJ2tL2SAHRDp2HfIml1cX+1pMfaKQdAt9R+Zrf9sKRlkubaPijpdkl3SfqW7TWSDki6oZtFTnV1/WKpuuc743tTs5det1/qfn/QRF0ffc5nqtc/3WItbakNe0SsKhm6uuVaAHQRP5cFkiDsQBKEHUiCsANJEHYgCU5xHQDH/3jq/s9Q1T7703+obine89ZmrbVPvlK+7T2fr57K+qKaduYgttbqcGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmboP3HHLBf59qtH5VL7vp6a/TFl9SOX7J5gOV41W98q2/mlm57rsf+ETl+Ds3v1Y5frpi2uWpfIntMhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJj03o0hsXek5cYS5Ke7Z+sa261/3jJd8uHVvxwepLIr/81xdXjr/w8c6nPZak936hvFc+9ytPNHptvNmu2KFjcdQTjXFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkOJ/9HHDRivLzsiVJr5QPbdtZ3oOfjKbnlM/dRy99UNQe2W1vtD1qe++4ZXfYPmR7d/G3ortlAmhqMm/jvybp2gmW3x0RS4q/be2WBaBttWGPiMclHe1BLQC6qMkXdOts7yne5s8ue5LtYdsjtkdO6kSDzQFootOw3y/pXZKWSDos6YtlT4yI9RExFBFD0zWjw80BaKqjsEfEkYg4HRG/kbRB0tJ2ywLQto7Cbnv+uIcfkbS37LkABkNtn932w5KWSZpr+6Ck2yUts71EUkjaL+mmLtaY3oE731/zjPJ5zqvmKJeke95aff30Jtdmx2CpDXtErJpg8YNdqAVAF/FzWSAJwg4kQdiBJAg7kARhB5LgFNcBsHhkeuX4L0ar21/L1qwtHaubsnnZ8vJ1JelzWx+qHF+388bK8cvW5psaeVBxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJOizt2Da4uoplY8sq54Wua6PXnsp6Qbq+vD3XffhyvGf7txQOX6Nlpx1TegOjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAR99hbcvPW7leO3/dPfVo53s4/eFJeKnjo4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEvTZJ6l62uQXKted+5Un2i2mh+rO1a+aLhqDpfbIbnuh7Z22n7P9rO1PFcvn2N5u+8Xidnb3ywXQqcm8jT8l6bMRcbmkKyXdbPtySbdI2hERl0raUTwGMKBqwx4RhyPi6eL+cUnPS1ogaaWkTcXTNkm6vltFAmjurD6z2367pPdI2iVpXkQcLoZelTSvZJ1hScOSNFPnd1ongIYm/W287bdI+o6kT0fEsfFjERGSYqL1ImJ9RAxFxNB0zWhULIDOTSrstqdrLOibI+KRYvER2/OL8fmSRrtTIoA21L6Nt21JD0p6PiK+NG5oi6TVku4qbh/rSoXngLpTWOdqcFtvda21utN3t/5qZpvloIsm85n9A5JulPSM7TNN1Vs1FvJv2V4j6YCkG7pTIoA21IY9In4kySXDV7dbDoBu4eeyQBKEHUiCsANJEHYgCcIOJMEprpP0wsfvLx1btmZtDys5OyeWv69y/HP3PtTo9eumdJa4FPWg4MgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nQZ5+k937hE6Vjd9771cp16853rzN95WuV4z9e8u2K0epLPb/7gfJ/lyQtuq3uXHz66OcKjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kITHJnPpjQs9J67w1Lsg7U82VJ8zPm/B/1SOV/fJpSt3f7Ry/ORjF5dv+4fVPfrT++iTTyW7YoeOxdEJrwbNkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkqjts9teKOnrkuZJCknrI+LLtu+QtFbSmUburRGxreq1pmqfHRgUVX32yVy84pSkz0bE07YvkPSU7e3F2N0R8c9tFQqgeyYzP/thSYeL+8dtPy9pQbcLA9Cus/rMbvvtkt4jaVexaJ3tPbY32p5dss6w7RHbIyd1olGxADo36bDbfouk70j6dEQck3S/pHdJWqKxI/8XJ1ovItZHxFBEDE3XjBZKBtCJSYXd9nSNBX1zRDwiSRFxJCJOR8RvJG2QtLR7ZQJoqjbsti3pQUnPR8SXxi2fP+5pH5G0t/3yALRlMt/Gf0DSjZKesX3musS3Slple4nG2nH7Jd3UlQoBtGIy38b/SNJEfbvKnjqAwcIv6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dMpm269JOjBu0VxJP+9ZAWdnUGsb1LokautUm7UtiogJ5/DuadjftHF7JCKG+lZAhUGtbVDrkqitU72qjbfxQBKEHUii32Ff3+ftVxnU2ga1LonaOtWT2vr6mR1A7/T7yA6gRwg7kERfwm77Wtv7bL9k+5Z+1FDG9n7bz9jebXukz7VstD1qe++4ZXNsb7f9YnE74Rx7fartDtuHin232/aKPtW20PZO28/Zftb2p4rlfd13FXX1ZL/1/DO77WmSfiLpLyUdlPSkpFUR8VxPCylhe7+koYjo+w8wbP+FpF9K+npE/Emx7B8lHY2Iu4r/o5wdEX83ILXdIemX/Z7Gu5itaP74acYlXS/pb9THfVdR1w3qwX7rx5F9qaSXIuLliHhd0jclrexDHQMvIh6XdPQNi1dK2lTc36Sx/1h6rqS2gRARhyPi6eL+cUlnphnv676rqKsn+hH2BZJ+Nu7xQQ3WfO8h6Qe2n7I93O9iJjAvIg4X91+VNK+fxUygdhrvXnrDNOMDs+86mf68Kb6ge7OrIuLPJS2XdHPxdnUgxdhnsEHqnU5qGu9emWCa8d/q577rdPrzpvoR9kOSFo57/LZi2UCIiEPF7aikRzV4U1EfOTODbnE72ud6fmuQpvGeaJpxDcC+6+f05/0I+5OSLrX9DtvnSfqYpC19qONNbM8qvjiR7VmSPqTBm4p6i6TVxf3Vkh7rYy2/Y1Cm8S6bZlx93nd9n/48Inr+J2mFxr6R/y9Jf9+PGkrqeqek/yz+nu13bZIe1tjbupMa+25jjaQ/lLRD0ouS/k3SnAGq7SFJz0jao7Fgze9TbVdp7C36Hkm7i78V/d53FXX1ZL/xc1kgCb6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/h/zxDZL2Ps7OAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbKzoZHRfDgH"
      },
      "source": [
        "##define the RMSprop model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjHmnJ9UfNtR"
      },
      "source": [
        "# Set the CNN RMSprop \n",
        "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "\n",
        "RMSpropmodel = Sequential()\n",
        "\n",
        "RMSpropmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "RMSpropmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "RMSpropmodel.add(MaxPool2D(pool_size=(2,2)))\n",
        "RMSpropmodel.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "RMSpropmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "RMSpropmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "RMSpropmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "RMSpropmodel.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "RMSpropmodel.add(Flatten())\n",
        "RMSpropmodel.add(Dense(256, activation = \"relu\"))\n",
        "RMSpropmodel.add(Dropout(0.5))\n",
        "RMSpropmodel.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-H8BfYbfT9Y"
      },
      "source": [
        "# Define the optimizer\n",
        "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "# Compile the RMSprop\n",
        "RMSpropmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics='accuracy')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ_9242wfyhC"
      },
      "source": [
        "epochs = 10 # Turn epochs to 30 to get 0.9967 accuracy # tooooo long run time\n",
        "batch_size = 86"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miJpLqc8gA1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07aeff0-c596-4c88-efd8-161c4124d50a"
      },
      "source": [
        "# Fit the RMSprop\n",
        "RMShistory = RMSpropmodel.fit(X_train,Y_train, batch_size=batch_size,\n",
        "                              epochs = epochs, validation_data = (X_test,Y_test),verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhFDrRk1kzO0"
      },
      "source": [
        "###evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ-MbIg0OwLm"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix\n",
        "predict = RMSpropmodel.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(Y_test.argmax(axis=1), predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnlOKLrFdBiK"
      },
      "source": [
        "همانطور که مشخص است دقت بالای 99 درصد حاصل شد در نهایت.مقادیر متفاوت این متغیرهای آماری که در فصل 5 گزارش توضیح داده شدند، هم مقادیر بالایی را نشان می‌دهند به جز مقدار precision برای ارقام 8 و 9  که به ترتیب در 4 و 3 درصد مواقع به یک لیبل فالس برای این ارقام، اشتباها لیبل ترو نسبت می‌دهد. به همین دلیل مقدار f1-score این دو نیز 98 درصد است که میانگین نرخ‌های فوق و است و طبیعتا کاهش میابد.\n",
        "عدد 4 نیز racall با خطای 2 درصد دارد که به آن معناست که در 2 درصد مواقع اعدادی که واقعا 4 بودند، چیز دیگری تشخیص داده شده‌اند."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbY4rO8KJf6q"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = RMSpropmodel.predict(X_test)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_test,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SqWfL4ne16n"
      },
      "source": [
        "همانطور که درگزارش نیز بیان شد، در اینجا نشان داده می‌شود که هر رقم چند بار به چه رقمی تشخیص داده شده است. به طور کلی اکثر ارقام درست تشخیص داده شده‌اند. بیشترین نرخ اشتباه همانطور که در بالا هم گویا بود، مربوط به پیشگویی ارقام 8 و 9 است. رقم 8 اشتباها 5 بار به جای 2، و 5 بار به جای 3 شناخته شده و رقم 9 . اشتباها 6 بار به جای 4 و 3 بار به جای 7 شناخته شده است. سایر اشتباهات 1 یا 2 بار رخ داده‌اند و در مجموع 43 تشخیص اشتباه از بین 4200 داده تست اشتباه تشخیص داده شده‌اند که 16 مورد برای تشخیص 0 تا 7 بوده و سایر 27 اشتباه در تشخیص 8 و 9 بوده. یعنی 8  و 9 ارقامی هستند که برای این ممکن است بیشتر به جای ارقام دیگر شناخته شوند. پس اگر در تسخیص رقمی ورودی، جواب 8 یا 9 دریافت کردیم، 3-4 درصد احتمال دهیم که رقم اشتباه تشخیص داده شده و شاید بهتر باشد از مدلی که در تشخیص، کمتر این خطا را میکند، استفاده کنیم.\n",
        "اعداد با رقم واقعی 1 و 4 نیز بیشترین بار تشخیص داد نشده‌اند و اشتباها چیز دیگری تشخیص داده شده‌اند که رقم 4 طبق گزارش بالا انتظار میرفت اما 1 نه. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZz0kBt09fz9"
      },
      "source": [
        "مدل زیر با تغییر یک لایه شبکه، نتیجه بهتری حاصل کرد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTXP5a9d-pFN"
      },
      "source": [
        "##define the Adam model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3vVcaNY-syX"
      },
      "source": [
        "# Set the CNN adam\n",
        "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "AdamModel = Sequential()\n",
        "\n",
        "AdamModel.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', input_shape = (28,28,1)))\n",
        "AdamModel.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu'))\n",
        "AdamModel.add(MaxPool2D(pool_size=(2,2)))\n",
        "AdamModel.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "AdamModel.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
        "AdamModel.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
        "AdamModel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "AdamModel.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "AdamModel.add(Flatten())\n",
        "AdamModel.add(Dense(256, activation = \"relu\"))\n",
        "AdamModel.add(Dropout(0.5))\n",
        "AdamModel.add(Dense(10, activation = \"softmax\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7aldVqChz1"
      },
      "source": [
        "set the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPNpn-stCXvL"
      },
      "source": [
        "# Define the optimizer\n",
        "# Compile the adam\n",
        "AdamModel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYuts_aVEkgh"
      },
      "source": [
        "# Fit the adam\n",
        "Adamhistory = AdamModel.fit(X_train,Y_train, batch_size=batch_size,\n",
        "                              epochs = epochs, validation_data = (X_test,Y_test),verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trk04MdvlMBE"
      },
      "source": [
        "###evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ByqK7hayqi"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix\n",
        "predict = AdamModel.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(Y_test.argmax(axis=1), predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQkyv6Yvh2oD"
      },
      "source": [
        "مشاهده می‌کنیم که این مدل برای هیچ رقمی خطای بالای 2 درصد ندارد. درست است که مثل مدل قبل دقت نهایی آن 99 درصد است اما روی یک رقم خاص خطای بالاتر ندارد. خطاهای 2 درصد هم برای precision رقم 8 رخ داده که نشان میدهد در 2 درصد مواقع اشتباه به یک لیبل فالس برای رقم 8 اشتباها ترو داده میشود. مانند مدل قبل اما این بار با خطای کمتر. همچنین یک خطای 2 درصد هم در recall رقم 9 دیده می‌شود که نشان می‌دهد این مدل در سافتن همه    9ها  2درصد خطا دارد."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w0OGFx3E4i8"
      },
      "source": [
        "confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od3U3sACE4EV"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = AdamModel.predict(X_test)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_test,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFgIcs5ijGAp"
      },
      "source": [
        "اینجا به طرز مشهودی نشخیص اشتباه در هیچ رقمی بالای 2 بار رویت نمیشود. طبق انتطار از نتایج بالا، رقم 8 بیشترین مجموع خطای تشخیص را دارد (ستون 8) و رقم 9 بیشترین مقدار تشخیص داده نشدن (سطر 9 یا ارقامی که واقعا 9 بودند اما چیز دیگری شناخته شدند)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtWAgxq-brOs"
      },
      "source": [
        "plt.plot(range(10) , RMShistory.history['accuracy'] , label=\"RMSprop\")\n",
        "plt.plot(range(10) , Adamhistory.history['accuracy'] , label=\"adam\")\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80bxU6-VktSb"
      },
      "source": [
        "همانطور که در گزارش نیز بیان شده، از آنجا که مدل دوم از ترکیب مدل اول با مدل دیگری به دست آمده و همچنین از گزارش‌های بالا، انتظار میرفت که به طور کلی دقت بالاتری داشه باشد اما نتایج نشان میدهد تا رقم 6 این دقت تشخیص در مدل اول بهتر بوده. البته اگر مدل‌ها را روی مقادیر آماری دیگر به جز accuraccy\n",
        "فیت میکردیم، نتایج تفاوت میکرد. همانطور که در بالا هم توضیح دادیم مدل آدام در مجموع خطای پایینتری داشت. برای مثال اگر مدل را روی precision\n",
        "فیت میکردیم، نتایج متفاوت‌تر میشد زیرا مدل دوم برای ارقام کوچکتر دقت 100درصدی دارد."
      ]
    }
  ]
}